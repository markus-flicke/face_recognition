{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "The following document carries out a leave one out cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.FaceRecogniser import recognise_lbp_hog\n",
    "from src.FaceRecogniser.create_training_set import create_training_set\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from src import Config\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(os.path.join('dat', 'labels.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reappearing labels\n",
    "* Persons can only be recognised in the test set, if they are seen at least once in the training dataset.  \n",
    "    * Thus, the total dataset must have these people on two different photos.  \n",
    "* Reappearing labels are candidates for the test data point during leave one out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reappearing_labels(labels_df):\n",
    "    return [label for label in labels_df.label.unique() if labels_df.label.value_counts()[label] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(filename, labels_df):\n",
    "    training_set_df = labels_df[labels_df.filename != filename]\n",
    "    training_filenames = training_set_df.filename.tolist()\n",
    "    training_labels = training_set_df.label.tolist()\n",
    "    create_training_set(training_filenames, training_labels)\n",
    "    \n",
    "    id, conf = recognise_lbp_hog.predict(filename)\n",
    "    return id, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv_contrib/modules/face/src/eigen_faces.cpp:72: error: (-210:Unsupported format or combination of formats) In the Eigenfaces method all input samples (training images) must be of equal size! Expected 5476 pixels, but was 33489 pixels. in function 'train'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c576da6c8fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreappearing_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Do Leave one out Cross Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8716855dde4b>\u001b[0m in \u001b[0;36mpredict_label\u001b[0;34m(filename, labels_df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcreate_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognise_lbp_hog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/face_recognition/code/src/FaceRecogniser/create_training_set.py\u001b[0m in \u001b[0;36mcreate_training_set\u001b[0;34m(training_filenames, training_labels)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mrecognizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEigenFaceRecognizer_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# LBPHFaceRecognizer_create()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv_contrib/modules/face/src/eigen_faces.cpp:72: error: (-210:Unsupported format or combination of formats) In the Eigenfaces method all input samples (training images) must be of equal size! Expected 5476 pixels, but was 33489 pixels. in function 'train'\n"
     ]
    }
   ],
   "source": [
    "reappearing_labels = get_reappearing_labels(labels_df)\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "for i, row in enumerate(labels_df.values):\n",
    "    if row[1] in reappearing_labels:\n",
    "        # Do Leave one out Cross Validation\n",
    "        id, conf = predict_label(row[0], labels_df)\n",
    "        predictions.append(id)\n",
    "        ground_truth.append(row[1])\n",
    "#         print(f'Ground truth label: {row[1]}')\n",
    "#         print(f'Predicted label: {id}\\n Prediction Confidence: {conf}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy sucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Mistakes\n",
    "* Clearly the images have a bad resolution\n",
    "    * I think this is the major bottleneck\n",
    "* Some people are not directly facing the camera\n",
    "* Few images are not faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 0\n",
    "plt.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams['ytick.labelsize'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 5\n",
    "rows = len([1 for i in range(len(predictions)) if predictions[i] != ground_truth[i]])//cols+1\n",
    "\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (20,20))\n",
    "path = Config.EXTRACTED_FACES_PATH\n",
    "img_idx = 0\n",
    "\n",
    "predictions_idx = 0\n",
    "for i, row in enumerate(labels_df.values):\n",
    "    if row[1] in reappearing_labels:\n",
    "        if predictions[predictions_idx] != ground_truth[predictions_idx]:\n",
    "            img = cv2.imread(os.path.join(path, row[0]))\n",
    "            ax[img_idx%rows][img_idx//rows].imshow(img)\n",
    "            img_idx += 1\n",
    "        predictions_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification successes\n",
    "* Duplication of pictures led to a higher accuracy\n",
    "    * 7/25 were not duplicates\n",
    "* The silver lining is that face recognition works great when it's the same image\n",
    "    * Hence it does work, just not that well\n",
    "* Not sure how to automatically remove duplicates...\n",
    "    * Could just do that by hand\n",
    "    * But any manual process in the pipeline will be hard to automate later\n",
    "    * Let's just say for now, that the lbg_hog algorithm wasnt very successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 5\n",
    "rows = len([1 for i in range(len(predictions)) if predictions[i] == ground_truth[i]])//cols+1\n",
    "\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (20,20))\n",
    "path = Config.EXTRACTED_FACES_PATH\n",
    "img_idx = 0\n",
    "\n",
    "predictions_idx = 0\n",
    "for i, row in enumerate(labels_df.values):\n",
    "    if row[1] in reappearing_labels:\n",
    "        if predictions[predictions_idx] == ground_truth[predictions_idx]:\n",
    "            img = cv2.imread(os.path.join(path, row[0]))\n",
    "            ax[img_idx%rows][img_idx//rows].imshow(img)\n",
    "            img_idx += 1\n",
    "        predictions_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
