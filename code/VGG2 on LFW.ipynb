{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the VGG Face2 Algorithm on A2\n",
    "The following document carries out a leave one out cross validation on Andreas Karges Album 2.\n",
    "\n",
    "Install VGGFace2 by executing:\n",
    "\n",
    "- pip install git+https://github.com/JohannesZahn/keras-vggface.git \n",
    "- pip install tensorflow==1.14.0\n",
    "- pip install keras = 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src import Config\n",
    "import cv2\n",
    "import keras_vggface\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n\n",
      "WARNING:tensorflow:From C:\\Users\\Johan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = VGGFace(model='resnet50', include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(Config.ANDREAS_ALBUMS_PATH / \"labels.csv\")\n",
    "imageNames = os.listdir(Config.EXTRACTED_FACES_PATH)\n",
    "imageCount = len(imageNames)\n",
    "faces= np.zeros((imageCount, 224,224,3), dtype=np.float32)\n",
    "for idx, image_name in enumerate(imageNames):\n",
    "    image= cv2.imread(str(Config.EXTRACTED_FACES_PATH/image_name))\n",
    "    resizedImage = cv2.resize(image, dsize=(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    faces[idx, :,:,:] = resizedImage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "01_0_0.png 01_0_0.png\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tf.convert_to_tensor(faces,dtype=tf.float32)\n",
    "embeddings = model.predict(faces)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reappearing labels\n",
    "* Persons can only be recognised in the test set, if they are seen at least once in the training dataset.  \n",
    "    * Thus, the total dataset must have these people on two different photos.  \n",
    "* Reappearing labels are candidates for the test data point during leave one out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_reappearing_labels(labels_df):\n",
    "    return [label for label in labels_df.label.unique() if labels_df.label.value_counts()[label] >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-280ecbbdac7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreappearing_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Do Leave one out Cross Validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mground_truth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-ab314761af85>\u001b[0m in \u001b[0;36mpredict_label\u001b[1;34m(filename, labels_df)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtraining_filenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtraining_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_opencv_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognise_lbp_hog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_lbph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\Tübingen\\Semester 2\\Praktikum\\face_recognition\\code\\src\\FaceRecogniser\\train_opencv_classifier.py\u001b[0m in \u001b[0;36mtrain_opencv_classifier\u001b[1;34m(training_filenames, training_labels, classifier, training_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \"\"\"\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# The lbph face recogniser will be called 'opencv_lbphfaces'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\Tübingen\\Semester 2\\Praktikum\\face_recognition\\code\\src\\FaceRecogniser\\train_opencv_classifier.py\u001b[0m in \u001b[0;36m_open_images\u001b[1;34m(training_filenames, path)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagePath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfaceImg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mfaceNp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceImg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceNp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dat\\\\AndreasAlbums\\\\extracted_faces\\\\01_1_0.png'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dat\\\\AndreasAlbums\\\\extracted_faces\\\\01_1_0.png'",
     "output_type": "error"
    }
   ],
   "source": [
    "reappearing_labels = get_reappearing_labels(labels_df)\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "for idx1, embedding1 in enumerate(embeddings):\n",
    "    for idx2, embedding2 in enumerate(embeddings):\n",
    "        if idx1!=idx2 and cosine(embedding1,embedding1)<0.3:\n",
    "            label = labels_df.loc[labels_df['filename'] == imageNames[idx1]]['label']\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "for i, row in enumerate(labels_df.values):\n",
    "    if row[1] in reappearing_labels:\n",
    "        # Do Leave one out Cross Validation\n",
    "        id, conf = predict_label(row[0], labels_df)\n",
    "        predictions.append(id)\n",
    "        ground_truth.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predictions, ground_truth)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting the accuracy for duplicates (explanation below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "N = len(predictions)\n",
    "N_duplicates = 22\n",
    "((acc * N)-N_duplicates)/(N-N_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Mistakes\n",
    "* Clearly the images have a bad resolution\n",
    "    * I think this is the major bottleneck\n",
    "* Some people are not directly facing the camera\n",
    "* Few images are not faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 0\n",
    "plt.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams['ytick.labelsize'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This image** was recognised as similar to **These images** but should have been classified as **Those images**.   \n",
    "\n",
    "Image | Prediction class | Target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def row_in_plot(row, ax, prediction_label):\n",
    "    for i in range(5):\n",
    "        ax[i].axis('off')\n",
    "        \n",
    "    img = cv2.imread(os.path.join(path, row[0]))\n",
    "    ax[0].title.set_text(row[0])\n",
    "    ax[0].imshow(img)\n",
    "\n",
    "    # Prediction class representation\n",
    "    subset_df = labels_df[(labels_df.label == prediction_label) & (labels_df.filename != row[0])]\n",
    "    prediction_class_filenames = subset_df.filename.tolist()\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[1].title.set_text(prediction_class_filenames[0])\n",
    "    ax[1].imshow(img)\n",
    "\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[2].title.set_text(prediction_class_filenames[-1])\n",
    "    ax[2].imshow(img)\n",
    "    \n",
    "    # Prediction class representation\n",
    "    subset_df = labels_df[(labels_df.label == row[1]) & (labels_df.filename != row[0])]\n",
    "    prediction_class_filenames = subset_df.filename.tolist()\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[3].title.set_text(prediction_class_filenames[0])\n",
    "    ax[3].imshow(img)\n",
    "\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[4].title.set_text(prediction_class_filenames[-1])\n",
    "    ax[4].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cols = 5\n",
    "# Never let rows < 2, as then pyplot decides to have a 1D list of axes, rather than 2D. (>.<)\n",
    "rows = len([1 for i in range(len(predictions)) if predictions[i] != ground_truth[i]])\n",
    "\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (20,rows * 10))\n",
    "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=-0.3)\n",
    "fig.suptitle('        Test img          |                            Prediction class                    |                           Target class               ', \n",
    "             fontsize=20, y = 0.6)\n",
    "\n",
    "path = Config.EXTRACTED_FACES_PATH\n",
    "predictions_idx = 0\n",
    "row_idx = 0\n",
    "\n",
    "for i, row in enumerate(labels_df.values):\n",
    "    # if it reappears, then there is a prediction for it\n",
    "    if row[1] in reappearing_labels:\n",
    "        # if the prediction is wrong\n",
    "        if predictions[predictions_idx] != ground_truth[predictions_idx] and row_idx < rows:\n",
    "            row_in_plot(row, ax[row_idx], predictions[predictions_idx])\n",
    "            row_idx += 1\n",
    "        predictions_idx += 1\n",
    "plt.savefig('LBPH mistakes on A2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification successes\n",
    "* Duplication of pictures led to a higher accuracy\n",
    "    * 16/28 were duplicates\n",
    "* The silver lining is that face recognition works great when it's the same image\n",
    "    * Hence it does work, just not that well\n",
    "* Not sure how to automatically remove duplicates...\n",
    "    * Could just do that by hand\n",
    "    * But any manual process in the pipeline will be hard to automate later\n",
    "    * Let's just say for now, that the lbg_hog algorithm wasnt very successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def row_in_plot2(row, ax, prediction_label):\n",
    "    for i in range(5):\n",
    "        ax[i].axis('off')\n",
    "        \n",
    "    img = cv2.imread(os.path.join(path, row[0]))\n",
    "    ax[0].title.set_text(row[0])\n",
    "    ax[0].imshow(img)\n",
    "\n",
    "    # Target class representation\n",
    "    subset_df = labels_df[(labels_df.label == row[1]) & (labels_df.filename != row[0])]\n",
    "    prediction_class_filenames = subset_df.filename.tolist()\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[1].title.set_text(prediction_class_filenames[0])\n",
    "    ax[1].imshow(img)\n",
    "\n",
    "    img = cv2.imread(os.path.join(path, prediction_class_filenames[0]))\n",
    "    ax[2].title.set_text(prediction_class_filenames[-1])\n",
    "    ax[2].imshow(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cols = 5\n",
    "# Never let rows < 2, as then pyplot decides to have a 1D list of axes, rather than 2D. (>.<)\n",
    "rows = len([1 for i in range(len(predictions)) if predictions[i] == ground_truth[i]])\n",
    "\n",
    "fig, ax = plt.subplots(rows, cols, figsize = (20,rows * 10))\n",
    "plt.subplots_adjust(bottom=0.2, top=0.6, hspace=-0.3)\n",
    "fig.suptitle('Test img        |                           Target class                                                                                     ', \n",
    "             fontsize=20, y = 0.6)\n",
    "\n",
    "path = Config.EXTRACTED_FACES_PATH\n",
    "predictions_idx = 0\n",
    "row_idx = 0\n",
    "\n",
    "for i, row in enumerate(labels_df.values):\n",
    "    # if it reappears, then there is a prediction for it\n",
    "    if row[1] in reappearing_labels:\n",
    "        # if the prediction is wrong\n",
    "        if predictions[predictions_idx] == ground_truth[predictions_idx] and row_idx < rows:\n",
    "            row_in_plot2(row, ax[row_idx], predictions[predictions_idx])\n",
    "            row_idx += 1\n",
    "        predictions_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction Failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the success cases, occasionally the same face is extracted twice. The following section will outline some of those failures of the face extraction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_two_pics(filename1, filename2, path = Config.EXTRACTED_PHOTOS_PATH):\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (8,20))\n",
    "    img = cv2.imread(os.path.join(path, filename1))\n",
    "    ax[0].imshow(img)\n",
    "    img = cv2.imread(os.path.join(path, filename2))\n",
    "    ax[1].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failure: Photo extraction contains multiple photos\n",
    "Occasionally, the photo extractor crops a too large section of the album page. This leads to inclusion of multiple photos in the extracted 'single photo'.  \n",
    "Note, that both of the images of each pair displayed below was extracted as a \"photo\". The ones on the right are incorrectly extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_two_pics('45_2.png', '45_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_two_pics('08_1.png', '08_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_two_pics('06_0.png', '06_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_two_pics('02_1.png', '02_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_two_pics('08_1.png', '08_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}